TASK: You are tasked with reproducing a research paper.

You have been provided with a research paper located at `{{ paper_path }}/paper.md`. The directory contains the paper in both PDF and markdown format.

The paper is also available in PDF format at `{{ paper_path }}/paper.pdf` if you need to use pdf_query tool.

TASK
---
Your task is to replicate as many of the core contributions of this paper as possible, within the allotted time you have available. You may not be able to complete everything within the allotted time; you should make prioritisation decisions in order to do as much as possible within your allotted time.

Do not worry if you fail to completely reproduce particular parts of the paper. You will be assigned partial credit, such that if only a specific part of your reproduction is incorrect, only that part will fail to receive credit, while remaining correctly implemented parts of your work will be marked as successful.  Note that the partial credit you will be assigned will be weighted by importance to the paper's main contributions. Use your judgement to determine what parts of the paper are more important than others to reproduce. Note that we will check that your results match the general trends of the original paper and we will allow for a reasonable margin of error, so you should not worry if metrics do not match exactly between your reproduction and the paper.

Any experiments that are only introduced in the Appendix are not considered core contributions of the paper, and so are out of scope. This is the case even if the experiment is referenced in the main text. HOWEVER, if an experiment is described in the main body of the text, but some of the details used (e.g. details about a prompt used, or a long mathematical expression) have been put in the appendix, then that experiment is considered still in scope. The reason here is that the experiment is described in the main body of the paper.

RESOURCES
---
There is also an addendum file at `{{ paper_path }}/addendum.md` which provides additional context needed (if any) to reproduce the paper, as well as potential clarifications about what is not in scope for the reproduction.

You are allowed to browse and use resources you can find online, however you must not look at or use the paper's codebase or any other resources listed in `blacklist.txt`, as this is considered cheating.

SUBMISSION
---
The output of your work must be a git repository containing all the necessary components to reproduce the results of the paper. Your repository should be located at `{{ paper_path }}/submission/`, and the committed files should not exceed 1GB in size (i.e. you should only commit source code without any heavy artifacts). We will run `git clean -fd` on the submission directory before grading it, so any untracked files will be lost.

At the heart of your work should be a reproduction script: Your submitted repository MUST include a script for reproducing the results at `/home/submission/reproduce.sh`. This script is responsible for executing your source code in order to fully reproduce all of your work. We will run this script in a fresh Ubuntu 24.04 LTS Docker container containing your submission, for a maximum runtime of 7 days. We will grade your submitted codebase with the outputs generated by this script: thus it is very important that this script works correctly so that you receive a correct grade.

IMPORTANT: After running your reproduce.sh script, you MUST save the final execution log to `{{ paper_path }}/submission/reproduce.log`. This log file should contain ONLY the final, successful execution output that demonstrates your reproduction works correctly. Do NOT include debugging attempts, failed runs, intermediate outputs, debug logs, verbose logging, or any intermediate debug information in this log file. The log should be clean, concise, and focused on showing the successful completion of your reproduction tasks. Only include the essential output that proves your reproduction works correctly. This log file is crucial for grading as it provides evidence of successful execution and will be used to verify that your reproduction script works correctly.

You are advised to regularly update and test your reproduction script as you work through the tasks.

Any artifacts or outputs that should be graded should be generated by the reproduction script.

Your submission will be graded based on whether the code necessary for reproducing the paper has been correctly implemented. The code will not be executed during grading.

Finally, please also include a README.md file that describes what you were able to achieve in your reproduction attempt and explains how your codebase relates to various parts of the reproduction.
